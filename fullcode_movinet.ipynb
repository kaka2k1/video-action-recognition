{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 20:51:44.552236: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-11 20:51:45.468682: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-11 20:51:46.990807: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-11 20:51:47.059026: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-11 20:51:47.059217: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-11 20:51:47.060275: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-11 20:51:47.060454: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-11 20:51:47.060599: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-11 20:51:47.791448: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-11 20:51:47.791672: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-11 20:51:47.791820: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-11 20:51:47.791954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9941 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-03-11 20:51:49.046148: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:425] Loaded runtime CuDNN library: 8.2.4 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2024-03-11 20:51:49.046968: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at cudnn_rnn_ops.cc:1762 : UNKNOWN: Fail to find the dnn implementation.\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Exception encountered when calling layer 'gru' (type GRU).\n\n{{function_node __wrapped__CudnnRNN_device_/job:localhost/replica:0/task:0/device:GPU:0}} Fail to find the dnn implementation. [Op:CudnnRNN]\n\nCall arguments received by layer 'gru' (type GRU):\n  • inputs=tf.Tensor(shape=(1, 10, 8), dtype=float32)\n  • mask=None\n  • training=None\n  • initial_state=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/huy/Desktop/phong/action_reco/fullcode_movinet.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/huy/Desktop/phong/action_reco/fullcode_movinet.ipynb#W0sZmlsZQ%3D%3D?line=160'>161</a>\u001b[0m gru \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mGRU(units\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, return_sequences\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, return_state\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/huy/Desktop/phong/action_reco/fullcode_movinet.ipynb#W0sZmlsZQ%3D%3D?line=162'>163</a>\u001b[0m inputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal(shape\u001b[39m=\u001b[39m[\u001b[39m1\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m8\u001b[39m]) \u001b[39m# (batch, sequence, channels)\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/huy/Desktop/phong/action_reco/fullcode_movinet.ipynb#W0sZmlsZQ%3D%3D?line=164'>165</a>\u001b[0m result, state \u001b[39m=\u001b[39m gru(inputs) \u001b[39m# Run it all at once\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/huy/Desktop/phong/action_reco/fullcode_movinet.ipynb#W0sZmlsZQ%3D%3D?line=166'>167</a>\u001b[0m first_half, state \u001b[39m=\u001b[39m gru(inputs[:, :\u001b[39m5\u001b[39m, :])   \u001b[39m# run the first half, and capture the state\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/huy/Desktop/phong/action_reco/fullcode_movinet.ipynb#W0sZmlsZQ%3D%3D?line=167'>168</a>\u001b[0m second_half, _ \u001b[39m=\u001b[39m gru(inputs[:,\u001b[39m5\u001b[39m:, :], initial_state\u001b[39m=\u001b[39mstate)  \u001b[39m# Use the state to continue where you left off.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/src/layers/rnn/base_rnn.py:556\u001b[0m, in \u001b[0;36mRNN.__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m inputs, initial_state, constants \u001b[39m=\u001b[39m rnn_utils\u001b[39m.\u001b[39mstandardize_args(\n\u001b[1;32m    552\u001b[0m     inputs, initial_state, constants, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_constants\n\u001b[1;32m    553\u001b[0m )\n\u001b[1;32m    555\u001b[0m \u001b[39mif\u001b[39;00m initial_state \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m constants \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 556\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    558\u001b[0m \u001b[39m# If any of `initial_state` or `constants` are specified and are Keras\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[39m# tensors, then add them to the inputs and temporarily modify the\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[39m# input_spec to include them.\u001b[39;00m\n\u001b[1;32m    562\u001b[0m additional_inputs \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnknownError\u001b[0m: Exception encountered when calling layer 'gru' (type GRU).\n\n{{function_node __wrapped__CudnnRNN_device_/job:localhost/replica:0/task:0/device:GPU:0}} Fail to find the dnn implementation. [Op:CudnnRNN]\n\nCall arguments received by layer 'gru' (type GRU):\n  • inputs=tf.Tensor(shape=(1, 10, 8), dtype=float32)\n  • mask=None\n  • training=None\n  • initial_state=None"
     ]
    }
   ],
   "source": [
    "\n",
    "import tqdm\n",
    "import random\n",
    "import pathlib\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import remotezip as rz\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from keras import layers\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "# Import the MoViNet model from TensorFlow Models (tf-models-official) for the MoViNet model\n",
    "from official.projects.movinet.modeling import movinet\n",
    "from official.projects.movinet.modeling import movinet_model\n",
    "\n",
    "def list_files_per_class(zip_url):\n",
    "  files = []\n",
    "  with rz.RemoteZip(URL) as zip:\n",
    "    for zip_info in zip.infolist():\n",
    "      files.append(zip_info.filename)\n",
    "  return files\n",
    "\n",
    "def get_class(fname):\n",
    "  return fname.split('_')[-3]\n",
    "\n",
    "def get_files_per_class(files):\n",
    "  files_for_class = collections.defaultdict(list)\n",
    "  for fname in files:\n",
    "    class_name = get_class(fname)\n",
    "    files_for_class[class_name].append(fname)\n",
    "  return files_for_class\n",
    "\n",
    "def download_from_zip(zip_url, to_dir, file_names):\n",
    "  with rz.RemoteZip(zip_url) as zip:\n",
    "    for fn in tqdm.tqdm(file_names):\n",
    "      class_name = get_class(fn)\n",
    "      zip.extract(fn, str(to_dir / class_name))\n",
    "      unzipped_file = to_dir / class_name / fn\n",
    "\n",
    "      fn = pathlib.Path(fn).parts[-1]\n",
    "      output_file = to_dir / class_name / fn\n",
    "      unzipped_file.rename(output_file,)\n",
    "\n",
    "def split_class_lists(files_for_class, count):\n",
    "  split_files = []\n",
    "  remainder = {}\n",
    "  for cls in files_for_class:\n",
    "    split_files.extend(files_for_class[cls][:count])\n",
    "    remainder[cls] = files_for_class[cls][count:]\n",
    "  return split_files, remainder\n",
    "\n",
    "def download_ufc_101_subset(zip_url, num_classes, splits, download_dir):\n",
    "  files = list_files_per_class(zip_url)\n",
    "  for f in files:\n",
    "    tokens = f.split('/')\n",
    "    if len(tokens) <= 2:\n",
    "      files.remove(f) # Remove that item from the list if it does not have a filename\n",
    "\n",
    "  files_for_class = get_files_per_class(files)\n",
    "\n",
    "  classes = list(files_for_class.keys())[:num_classes]\n",
    "\n",
    "  for cls in classes:\n",
    "    new_files_for_class = files_for_class[cls]\n",
    "    random.shuffle(new_files_for_class)\n",
    "    files_for_class[cls] = new_files_for_class\n",
    "\n",
    "  # Only use the number of classes you want in the dictionary\n",
    "  files_for_class = {x: files_for_class[x] for x in list(files_for_class)[:num_classes]}\n",
    "\n",
    "  dirs = {}\n",
    "  for split_name, split_count in splits.items():\n",
    "    print(split_name, \":\")\n",
    "    split_dir = download_dir / split_name\n",
    "    split_files, files_for_class = split_class_lists(files_for_class, split_count)\n",
    "    download_from_zip(zip_url, split_dir, split_files)\n",
    "    dirs[split_name] = split_dir\n",
    "\n",
    "  return dirs\n",
    "\n",
    "def format_frames(frame, output_size):\n",
    "  frame = tf.image.convert_image_dtype(frame, tf.float32)\n",
    "  frame = tf.image.resize_with_pad(frame, *output_size)\n",
    "  return frame\n",
    "\n",
    "def frames_from_video_file(video_path, n_frames, output_size = (224,224), frame_step = 15):\n",
    "  # Read each video frame by frame\n",
    "  result = []\n",
    "  src = cv2.VideoCapture(str(video_path))\n",
    "\n",
    "  video_length = src.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "  need_length = 1 + (n_frames - 1) * frame_step\n",
    "\n",
    "  if need_length > video_length:\n",
    "    start = 0\n",
    "  else:\n",
    "    max_start = video_length - need_length\n",
    "    start = random.randint(0, max_start + 1)\n",
    "\n",
    "  src.set(cv2.CAP_PROP_POS_FRAMES, start)\n",
    "  # ret is a boolean indicating whether read was successful, frame is the image itself\n",
    "  ret, frame = src.read()\n",
    "  result.append(format_frames(frame, output_size))\n",
    "\n",
    "  for _ in range(n_frames - 1):\n",
    "    for _ in range(frame_step):\n",
    "      ret, frame = src.read()\n",
    "    if ret:\n",
    "      frame = format_frames(frame, output_size)\n",
    "      result.append(frame)\n",
    "    else:\n",
    "      result.append(np.zeros_like(result[0]))\n",
    "  src.release()\n",
    "  result = np.array(result)[..., [2, 1, 0]]\n",
    "\n",
    "  return result\n",
    "\n",
    "class FrameGenerator:\n",
    "  def __init__(self, path, n_frames, training = False):\n",
    "    self.path = path\n",
    "    self.n_frames = n_frames\n",
    "    self.training = training\n",
    "    self.class_names = sorted(set(p.name for p in self.path.iterdir() if p.is_dir()))\n",
    "    self.class_ids_for_name = dict((name, idx) for idx, name in enumerate(self.class_names))\n",
    "\n",
    "  def get_files_and_class_names(self):\n",
    "    video_paths = list(self.path.glob('*/*.avi'))\n",
    "    classes = [p.parent.name for p in video_paths]\n",
    "    return video_paths, classes\n",
    "\n",
    "  def __call__(self):\n",
    "    video_paths, classes = self.get_files_and_class_names()\n",
    "\n",
    "    pairs = list(zip(video_paths, classes))\n",
    "\n",
    "    if self.training:\n",
    "      random.shuffle(pairs)\n",
    "\n",
    "    for path, name in pairs:\n",
    "      video_frames = frames_from_video_file(path, self.n_frames)\n",
    "      label = self.class_ids_for_name[name] # Encode labels\n",
    "      yield video_frames, label\n",
    "\n",
    "URL = 'https://storage.googleapis.com/thumos14_files/UCF101_videos.zip'\n",
    "download_dir = pathlib.Path('./UCF101_subset/')\n",
    "batch_size = 16\n",
    "num_frames = 10\n",
    "\n",
    "output_signature = (tf.TensorSpec(shape = (None, None, None, 3), dtype = tf.float32),\n",
    "                    tf.TensorSpec(shape = (), dtype = tf.int16))\n",
    "\n",
    "gru = layers.GRU(units=4, return_sequences=True, return_state=True)\n",
    "\n",
    "inputs = tf.random.normal(shape=[1, 10, 8]) # (batch, sequence, channels)\n",
    "\n",
    "result, state = gru(inputs) # Run it all at once\n",
    "\n",
    "first_half, state = gru(inputs[:, :5, :])   # run the first half, and capture the state\n",
    "second_half, _ = gru(inputs[:,5:, :], initial_state=state)  # Use the state to continue where you left off.\n",
    "\n",
    "print(np.allclose(result[:, :5,:], first_half))\n",
    "print(np.allclose(result[:, 5:,:], second_half))\n",
    "\n",
    "model_id = 'a0'\n",
    "resolution = 224\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "backbone = movinet.Movinet(model_id=model_id)\n",
    "backbone.trainable = False\n",
    "\n",
    "# Set num_classes=600 to load the pre-trained weights from the original model\n",
    "model = movinet_model.MovinetClassifier(backbone=backbone, num_classes=600)\n",
    "model.build([None, None, None, None, 3])\n",
    "\n",
    "# Load pre-trained weights\n",
    "!wget https://storage.googleapis.com/tf_model_garden/vision/movinet/movinet_a0_base.tar.gz -O movinet_a0_base.tar.gz -q\n",
    "!tar -xvf movinet_a0_base.tar.gz\n",
    "\n",
    "checkpoint_dir = f'movinet_{model_id}_base'\n",
    "checkpoint_path = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "checkpoint = tf.train.Checkpoint(model=model)\n",
    "status = checkpoint.restore(checkpoint_path)\n",
    "status.assert_existing_objects_matched()\n",
    "def build_classifier(batch_size, num_frames, resolution, backbone, num_classes):\n",
    "  \"\"\"Builds a classifier on top of a backbone model.\"\"\"\n",
    "  model = movinet_model.MovinetClassifier(\n",
    "      backbone=backbone,\n",
    "      num_classes=num_classes)\n",
    "  model.build([batch_size, num_frames, resolution, resolution, 3])\n",
    "\n",
    "  return model\n",
    "loss_obj = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "numclasses_list = list(range(85, 101, 5))  # [5, 10, ..., 95, 100, 101]\n",
    "\n",
    "import json\n",
    "def plot_history(history):\n",
    "  fig, (ax1, ax2) = plt.subplots(2)\n",
    "\n",
    "  fig.set_size_inches(18.5, 10.5)\n",
    "\n",
    "  # Plot loss\n",
    "  ax1.set_title('Loss')\n",
    "  ax1.plot(history.history['loss'], label = 'train')\n",
    "  ax1.plot(history.history['val_loss'], label = 'test')\n",
    "  ax1.set_ylabel('Loss')\n",
    "\n",
    "  # Determine upper bound of y-axis\n",
    "  max_loss = max(history.history['loss'] + history.history['val_loss'])\n",
    "\n",
    "  ax1.set_ylim([0, np.ceil(max_loss)])\n",
    "  ax1.set_xlabel('Epoch')\n",
    "  ax1.legend(['Train', 'Validation'])\n",
    "\n",
    "  # Plot accuracy\n",
    "  ax2.set_title('Accuracy')\n",
    "  ax2.plot(history.history['accuracy'],  label = 'train')\n",
    "  ax2.plot(history.history['val_accuracy'], label = 'test')\n",
    "  ax2.set_ylabel('Accuracy')\n",
    "  ax2.set_ylim([0, 1])\n",
    "  ax2.set_xlabel('Epoch')\n",
    "  ax2.legend(['Train', 'Validation'])\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "# plot_history(history)\n",
    "# model.evaluate(test_ds, return_dict=True)\n",
    "def get_actual_predicted_labels(dataset):\n",
    "  actual = [labels for _, labels in dataset.unbatch()]\n",
    "  predicted = model.predict(dataset)\n",
    "\n",
    "  actual = tf.stack(actual, axis=0)\n",
    "  predicted = tf.concat(predicted, axis=0)\n",
    "  predicted = tf.argmax(predicted, axis=1)\n",
    "\n",
    "  return actual, predicted\n",
    "def plot_confusion_matrix(actual, predicted, labels, ds_type):\n",
    "  cm = tf.math.confusion_matrix(actual, predicted)\n",
    "  ax = sns.heatmap(cm, annot=True, fmt='g')\n",
    "  sns.set(rc={'figure.figsize':(12, 12)})\n",
    "  sns.set(font_scale=1.4)\n",
    "  ax.set_title('Confusion matrix of action recognition for ' + ds_type)\n",
    "  ax.set_xlabel('Predicted Action')\n",
    "  ax.set_ylabel('Actual Action')\n",
    "  plt.xticks(rotation=90)\n",
    "  plt.yticks(rotation=0)\n",
    "  ax.xaxis.set_ticklabels(labels)\n",
    "  ax.yaxis.set_ticklabels(labels)\n",
    "\n",
    "def calculate_classification_metrics(y_actual, y_pred, labels):\n",
    "  cm = tf.math.confusion_matrix(y_actual, y_pred)\n",
    "  tp = np.diag(cm) # Diagonal represents true positives\n",
    "  precision = dict()\n",
    "  recall = dict()\n",
    "  for i in range(len(labels)):\n",
    "    col = cm[:, i]\n",
    "    fp = np.sum(col) - tp[i] # Sum of column minus true positive is false negative\n",
    "\n",
    "    row = cm[i, :]\n",
    "    fn = np.sum(row) - tp[i] # Sum of row minus true positive, is false negative\n",
    "\n",
    "    precision[labels[i]] = tp[i] / (tp[i] + fp) # Precision\n",
    "\n",
    "    recall[labels[i]] = tp[i] / (tp[i] + fn) # Recall\n",
    "\n",
    "  return precision, recall\n",
    "\n",
    "numclasses_list = list(range(85, 101, 5))  # [5, 10, ..., 95, 100, 101]\n",
    "\n",
    "for numclasses in numclasses_list:\n",
    "    with open(f'evaluate_CNN_{numclasses}.txt', 'w') as f:\n",
    "      # Download the subset of data\n",
    "      subsetpaths = download_ufc_101_subset(URL,\n",
    "                                        numclasses,\n",
    "                                        splits={\"train\": 30, \"val\": 10, \"test\": 10},\n",
    "                                        download_dir=download_dir)\n",
    "      \n",
    "      # Prepare the datasets\n",
    "      trainds = tf.data.Dataset.from_generator(FrameGenerator(subsetpaths['train'], num_frames, training=True), output_signature=output_signature)\n",
    "      trainds = trainds.batch(batch_size)\n",
    "      val_ds = tf.data.Dataset.from_generator(FrameGenerator(subsetpaths['val'], num_frames),\n",
    "                                                output_signature = output_signature)\n",
    "      val_ds = val_ds.batch(batch_size)\n",
    "      testds = tf.data.Dataset.from_generator(FrameGenerator(subsetpaths['test'], num_frames), output_signature=output_signature)\n",
    "      testds = testds.batch(batch_size)\n",
    "      \n",
    "      # Build the model\n",
    "      model = build_classifier(batch_size, num_frames, resolution, backbone, numclasses)\n",
    "      \n",
    "      # Compile and train the model\n",
    "      model.compile(loss=loss_obj, optimizer=optimizer, metrics=['accuracy'])\n",
    "      history = model.fit(trainds,\n",
    "                          validation_data=val_ds,\n",
    "                          epochs=10,\n",
    "                          validation_freq=1,\n",
    "                          verbose=1)\n",
    "\n",
    "      # Lưu các thông số vào tệp tin\n",
    "      f.write(json.dumps(history.history))\n",
    "      f.write('\\n')\n",
    "\n",
    "      # Đánh giá mô hình\n",
    "      results = model.evaluate(testds, return_dict=True)\n",
    "      f.write(json.dumps(results))\n",
    "      f.write('\\n')\n",
    "      # fg = FrameGenerator(subsetpaths['train'], num_frames, training=True)\n",
    "      # labels = list(fg.class_ids_for_name.keys())\n",
    "      # actual, predicted = get_actual_predicted_labels(trainds)\n",
    "      # plot_confusion_matrix(actual, predicted, labels, 'training')\n",
    "      # actual, predicted = get_actual_predicted_labels(testds)\n",
    "      # # Tính toán và lưu precision và recall\n",
    "      # actual, predicted = get_actual_predicted_labels(testds)\n",
    "      # precision, recall = calculate_classification_metrics(actual, predicted, labels)\n",
    "\n",
    "      # f.write('Precision:\\n')\n",
    "      # f.write(json.dumps(precision))\n",
    "      # f.write('\\n')\n",
    "      # f.write('Recall:\\n')\n",
    "      # f.write(json.dumps(recall))\n",
    "      # f.write('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phongenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
