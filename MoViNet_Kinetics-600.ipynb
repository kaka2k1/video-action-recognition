{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3352513,"sourceType":"datasetVersion","datasetId":2022849}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tf-models-official --quiet\n!pip install remotezip tqdm opencv-python einops --quiet\n# !pip install tensorflow","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-19T09:11:37.665904Z","iopub.execute_input":"2024-04-19T09:11:37.666283Z","iopub.status.idle":"2024-04-19T09:13:09.596027Z","shell.execute_reply.started":"2024-04-19T09:11:37.666230Z","shell.execute_reply":"2024-04-19T09:13:09.594897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tqdm\nimport random\nimport pathlib\nimport itertools\nimport collections\n\nimport cv2\nimport numpy as np\nimport remotezip as rz\n# import rarfile\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport json\nimport keras\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom keras import layers\nfrom keras.optimizers import Adam\nfrom keras.losses import SparseCategoricalCrossentropy\n\n# Import the MoViNet model from TensorFlow Models (tf-models-official) for the MoViNet model\nfrom official.projects.movinet.modeling import movinet\nfrom official.projects.movinet.modeling import movinet_model","metadata":{"execution":{"iopub.status.busy":"2024-04-19T09:13:09.598080Z","iopub.execute_input":"2024-04-19T09:13:09.598409Z","iopub.status.idle":"2024-04-19T09:13:12.874158Z","shell.execute_reply.started":"2024-04-19T09:13:09.598379Z","shell.execute_reply":"2024-04-19T09:13:12.873373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def list_files_per_class(zip_url):\n  files = []\n  with rz.RemoteZip(URL) as zip:\n    for zip_info in zip.infolist():\n      files.append(zip_info.filename)\n  return files\n\ndef get_class(fname):\n  return fname.split('_')[-3]\n\ndef get_files_per_class(files):\n  files_for_class = collections.defaultdict(list)\n  for fname in files:\n    class_name = get_class(fname)\n    files_for_class[class_name].append(fname)\n  return files_for_class\n\ndef download_from_zip(zip_url, to_dir, file_names):\n  with rz.RemoteZip(zip_url) as zip:\n    for fn in tqdm.tqdm(file_names):\n      class_name = get_class(fn)\n      zip.extract(fn, str(to_dir / class_name))\n      unzipped_file = to_dir / class_name / fn\n\n      fn = pathlib.Path(fn).parts[-1]\n      output_file = to_dir / class_name / fn\n      unzipped_file.rename(output_file,)\n\ndef split_class_lists(files_for_class, count):\n  split_files = []\n  remainder = {}\n  for cls in files_for_class:\n    split_files.extend(files_for_class[cls][:count])\n    remainder[cls] = files_for_class[cls][count:]\n  return split_files, remainder\n\ndef download_ufc_101_subset(zip_url, num_classes, splits, download_dir):\n  files = list_files_per_class(zip_url)\n  for f in files:\n    tokens = f.split('/')\n    if len(tokens) <= 2:\n      files.remove(f) # Remove that item from the list if it does not have a filename\n\n  files_for_class = get_files_per_class(files)\n\n  classes = list(files_for_class.keys())[:num_classes]\n\n  for cls in classes:\n    new_files_for_class = files_for_class[cls]\n    random.shuffle(new_files_for_class)\n    files_for_class[cls] = new_files_for_class\n\n  # Only use the number of classes you want in the dictionary\n  files_for_class = {x: files_for_class[x] for x in list(files_for_class)[:num_classes]}\n\n  dirs = {}\n  for split_name, split_count in splits.items():\n    print(split_name, \":\")\n    split_dir = download_dir / split_name\n    split_files, files_for_class = split_class_lists(files_for_class, split_count)\n    download_from_zip(zip_url, split_dir, split_files)\n    dirs[split_name] = split_dir\n\n  return dirs\n\ndef format_frames(frame, output_size):\n  frame = tf.image.convert_image_dtype(frame, tf.float32)\n  frame = tf.image.resize_with_pad(frame, *output_size)\n  return frame\n\ndef frames_from_video_file(video_path, n_frames, output_size = (224,224), frame_step = 15):\n  # Read each video frame by frame\n  result = []\n  src = cv2.VideoCapture(str(video_path))\n\n  video_length = src.get(cv2.CAP_PROP_FRAME_COUNT)\n\n  need_length = 1 + (n_frames - 1) * frame_step\n\n  if need_length > video_length:\n    start = 0\n  else:\n    max_start = video_length - need_length\n    start = random.randint(0, max_start + 1)\n    src.set(cv2.CAP_PROP_POS_FRAMES, start)\n  # ret is a boolean indicating whether read was successful, frame is the image itself\n  ret, frame = src.read()\n  result.append(format_frames(frame, output_size))\n\n  for _ in range(n_frames - 1):\n    for _ in range(frame_step):\n      ret, frame = src.read()\n    if ret:\n      frame = format_frames(frame, output_size)\n      result.append(frame)\n    else:\n      result.append(np.zeros_like(result[0]))\n  src.release()\n  result = np.array(result)[..., [2, 1, 0]]\n\n  return result","metadata":{"execution":{"iopub.status.busy":"2024-04-19T09:13:12.875238Z","iopub.execute_input":"2024-04-19T09:13:12.875744Z","iopub.status.idle":"2024-04-19T09:13:12.894414Z","shell.execute_reply.started":"2024-04-19T09:13:12.875718Z","shell.execute_reply":"2024-04-19T09:13:12.893564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nclass FrameGenerator:\n    def __init__(self, path, n_frames, n_classes, training = False):\n#     def __init__(self, path, n_frames, training = False):\n        self.path = path\n        self.n_frames = n_frames\n        self.n_classes = n_classes\n        self.training = training\n        self.class_names = os.listdir(path)\n        #     self.class_names = sorted(set(p.name for p in self.path.iterdir() if p.is_dir()))\n        self.class_ids_for_name = dict((name, idx) for idx, name in enumerate(self.class_names))\n\n    def get_all_avi(self, root_dir, classes):\n        lst_avi = []\n        lst_cls = []\n        # Iterate over each subfolder in the root directory\n        for folder_name in classes:\n            folder_path = os.path.join(root_dir, folder_name)\n\n            # Check if the item in the root directory is a directory\n            if os.path.isdir(folder_path):\n                # Iterate over each file in the subfolder\n                for file_name in os.listdir(folder_path):\n                    file_path = os.path.join(folder_path, file_name)\n\n                    # Check if the file is an AVI file\n                    if file_name.endswith('.mp4'):\n                        # Print the directory of the AVI file\n                        lst_avi.append(file_path)\n                        lst_cls.append(folder_name)\n#                         print(file_path)\n        return lst_avi, lst_cls\n    \n    def get_files_and_class_names(self):\n        classes = self.class_names[:self.n_classes]\n#         video_paths = self.get_all_avi(self.path, classes)\n        video_paths, lst_classes = self.get_all_avi(self.path, classes)\n        return video_paths, lst_classes\n\n    def __call__(self):\n        video_paths, classes = self.get_files_and_class_names()\n\n        pairs = list(zip(video_paths, classes))\n\n        if self.training:\n            random.shuffle(pairs)\n\n        for path, name in pairs:\n            video_frames = frames_from_video_file(path, self.n_frames)\n            label = self.class_ids_for_name[name] # Encode labels\n            yield video_frames, label","metadata":{"execution":{"iopub.status.busy":"2024-04-19T09:13:12.896315Z","iopub.execute_input":"2024-04-19T09:13:12.896622Z","iopub.status.idle":"2024-04-19T09:13:12.944575Z","shell.execute_reply.started":"2024-04-19T09:13:12.896600Z","shell.execute_reply":"2024-04-19T09:13:12.943643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"URL = 'https://storage.googleapis.com/thumos14_files/UCF101_videos.zip'\ndownload_dir = pathlib.Path('./UCF101_subset/')\nbatch_size = 16\nnum_frames = 10\noutput_signature = (tf.TensorSpec(shape = (None, None, None, 3), dtype = tf.float32),\n                    tf.TensorSpec(shape = (), dtype = tf.int16))","metadata":{"execution":{"iopub.status.busy":"2024-04-19T09:13:12.945683Z","iopub.execute_input":"2024-04-19T09:13:12.946013Z","iopub.status.idle":"2024-04-19T09:13:12.961676Z","shell.execute_reply.started":"2024-04-19T09:13:12.945981Z","shell.execute_reply":"2024-04-19T09:13:12.960910Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_id = 'a0'\nresolution = 224\n\ntf.keras.backend.clear_session()\n\nbackbone = movinet.Movinet(model_id=model_id)\nbackbone.trainable = False","metadata":{"execution":{"iopub.status.busy":"2024-04-19T09:13:12.962624Z","iopub.execute_input":"2024-04-19T09:13:12.962853Z","iopub.status.idle":"2024-04-19T09:13:47.831144Z","shell.execute_reply.started":"2024-04-19T09:13:12.962833Z","shell.execute_reply":"2024-04-19T09:13:47.830311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set num_classes=600 to load the pre-trained weights from the original model\nmodel = movinet_model.MovinetClassifier(backbone=backbone, num_classes=600)\nmodel.build([None, None, None, None, 3])","metadata":{"execution":{"iopub.status.busy":"2024-04-19T09:13:47.832346Z","iopub.execute_input":"2024-04-19T09:13:47.832644Z","iopub.status.idle":"2024-04-19T09:14:00.872189Z","shell.execute_reply.started":"2024-04-19T09:13:47.832618Z","shell.execute_reply":"2024-04-19T09:14:00.871428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Load pre-trained weights\n!wget https://storage.googleapis.com/tf_model_garden/vision/movinet/movinet_a0_base.tar.gz -O movinet_a0_base.tar.gz -q\n!tar -xvf movinet_a0_base.tar.gz","metadata":{"execution":{"iopub.status.busy":"2024-04-19T09:14:00.873387Z","iopub.execute_input":"2024-04-19T09:14:00.873722Z","iopub.status.idle":"2024-04-19T09:14:03.342005Z","shell.execute_reply.started":"2024-04-19T09:14:00.873691Z","shell.execute_reply":"2024-04-19T09:14:03.340836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_dir = f'movinet_{model_id}_base'\ncheckpoint_path = tf.train.latest_checkpoint(checkpoint_dir)\ncheckpoint = tf.train.Checkpoint(model=model)\nstatus = checkpoint.restore(checkpoint_path)\nstatus.assert_existing_objects_matched()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T09:14:03.343800Z","iopub.execute_input":"2024-04-19T09:14:03.344189Z","iopub.status.idle":"2024-04-19T09:14:03.755709Z","shell.execute_reply.started":"2024-04-19T09:14:03.344151Z","shell.execute_reply":"2024-04-19T09:14:03.754779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_classifier(batch_size, num_frames, resolution, backbone, num_classes):\n    \"\"\"Builds a classifier on top of a backbone model.\"\"\"\n    model = movinet_model.MovinetClassifier(\n      backbone=backbone,\n      num_classes=num_classes)\n    model.build([batch_size, num_frames, resolution, resolution, 3])\n\n    return model\nloss_obj = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n\noptimizer = keras.optimizers.Adam(learning_rate = 0.0001)\nnumclasses_list = list(range(85, 101, 5))  # [5, 10, ..., 95, 100, 101]","metadata":{"execution":{"iopub.status.busy":"2024-04-19T09:14:03.759235Z","iopub.execute_input":"2024-04-19T09:14:03.759602Z","iopub.status.idle":"2024-04-19T09:14:03.769382Z","shell.execute_reply.started":"2024-04-19T09:14:03.759578Z","shell.execute_reply":"2024-04-19T09:14:03.768567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\ndef plot_history(history):\n    fig, (ax1, ax2) = plt.subplots(2)\n\n    fig.set_size_inches(18.5, 10.5)\n\n    # Plot loss\n    ax1.set_title('Loss')\n    ax1.plot(history.history['loss'], label = 'train')\n    ax1.plot(history.history['val_loss'], label = 'test')\n    ax1.set_ylabel('Loss')\n\n    # Determine upper bound of y-axis\n    max_loss = max(history.history['loss'] + history.history['val_loss'])\n\n    ax1.set_ylim([0, np.ceil(max_loss)])\n    ax1.set_xlabel('Epoch')\n    ax1.legend(['Train', 'Validation'])\n\n    # Plot accuracy\n    ax2.set_title('Accuracy')\n    ax2.plot(history.history['accuracy'],  label = 'train')\n    ax2.plot(history.history['val_accuracy'], label = 'test')\n    ax2.set_ylabel('Accuracy')\n    ax2.set_ylim([0, 1])\n    ax2.set_xlabel('Epoch')\n    ax2.legend(['Train', 'Validation'])\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T09:14:03.770391Z","iopub.execute_input":"2024-04-19T09:14:03.770627Z","iopub.status.idle":"2024-04-19T09:14:03.780115Z","shell.execute_reply.started":"2024-04-19T09:14:03.770606Z","shell.execute_reply":"2024-04-19T09:14:03.779286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_actual_predicted_labels(dataset):\n    actual = [labels for _, labels in dataset.unbatch()]\n    predicted = model.predict(dataset)\n\n    actual = tf.stack(actual, axis=0)\n    predicted = tf.concat(predicted, axis=0)\n    predicted = tf.argmax(predicted, axis=1)\n\n    return actual, predicted\n\ndef plot_confusion_matrix(actual, predicted, labels, ds_type):\n    cm = tf.math.confusion_matrix(actual, predicted)\n    ax = sns.heatmap(cm, annot=True, fmt='g')\n    sns.set(rc={'figure.figsize':(12, 12)})\n    sns.set(font_scale=1.4)\n    ax.set_title('Confusion matrix of action recognition for ' + ds_type)\n    ax.set_xlabel('Predicted Action')\n    ax.set_ylabel('Actual Action')\n    plt.xticks(rotation=90)\n    plt.yticks(rotation=0)\n    ax.xaxis.set_ticklabels(labels)\n    ax.yaxis.set_ticklabels(labels)\n\ndef calculate_classification_metrics(y_actual, y_pred, labels):\n    cm = tf.math.confusion_matrix(y_actual, y_pred)\n    tp = np.diag(cm) # Diagonal represents true positives\n    precision = dict()\n    recall = dict()\n    for i in range(len(labels)):\n        col = cm[:, i]\n        fp = np.sum(col) - tp[i] # Sum of column minus true positive is false negative\n\n        row = cm[i, :]\n        fn = np.sum(row) - tp[i] # Sum of row minus true positive, is false negative\n\n        precision[labels[i]] = tp[i] / (tp[i] + fp) # Precision\n\n        recall[labels[i]] = tp[i] / (tp[i] + fn) # Recall\n\n    return precision, recall","metadata":{"execution":{"iopub.status.busy":"2024-04-19T09:14:03.781165Z","iopub.execute_input":"2024-04-19T09:14:03.781455Z","iopub.status.idle":"2024-04-19T09:14:03.795830Z","shell.execute_reply.started":"2024-04-19T09:14:03.781433Z","shell.execute_reply":"2024-04-19T09:14:03.795047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numclasses_list = list(range(75, 81, 5))  # [25, ..., 45, 50]\nsubsetpaths_train = \"/kaggle/input/kinetics-train-5per/kinetics600_5per/kinetics600_5per/train\"\nsubsetpaths_val = \"/kaggle/input/kinetics-train-5per/kinetics400_5per/kinetics400_5per/train\"\n\nfor numclasses in numclasses_list:\n    print(f\"-------------------- {numclasses} classes --------------------\")\n    with open(f'evaluate_CNN_{numclasses}.txt', 'w') as f:\n        trainds = tf.data.Dataset.from_generator(FrameGenerator(subsetpaths_train, num_frames, numclasses, training=True), output_signature=output_signature)\n        trainds = trainds.batch(batch_size)\n        \n        valds = tf.data.Dataset.from_generator(FrameGenerator(subsetpaths_val, num_frames, numclasses), output_signature=output_signature)\n        valds = valds.batch(batch_size)\n\n        # Build the model\n        model = build_classifier(batch_size, num_frames, resolution, backbone, numclasses)\n\n        # Compile and train the model\n        model.compile(loss=loss_obj, optimizer=\"adam\", metrics=['accuracy'])\n        history = model.fit(trainds,\n                          validation_data=trainds,\n                          epochs=10,\n                          validation_freq=1,\n                          verbose=1)\n\n        # Lưu các thông số vào tệp tin\n        f.write(json.dumps(history.history))\n        f.write('\\n')\n        model.save(f\"movinet_kinetic_10ep_{numclasses}.h5\")","metadata":{"execution":{"iopub.status.busy":"2024-04-19T09:14:03.796878Z","iopub.execute_input":"2024-04-19T09:14:03.797147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}